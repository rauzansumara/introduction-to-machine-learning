{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZIAkIlfmCe1B"
      },
      "source": [
        "# <font color = #4854E8> Linear Regression With scikit-learn </font>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get started, let's look at the simplest possible scenario: linear regression.\n",
        "\n",
        "When using linear regression, there are five fundamental steps to follow:\n",
        "\n",
        "1. First, make sure you've imported the required packages and classes.\n",
        "2. Second, give us some data to work with, and we'll get around to making the necessary adjustments.\n",
        "3. Third, build a regression model, and use it to explain the data you already have.\n",
        "4. Determine if the model is good by looking at the outcomes of the fitting procedure.\n",
        "5. Fifth, use the model to make forecasts.\n",
        "\n",
        "Most methods and implementations of regression share these commonalities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DzbtdRcZDO9B"
      },
      "source": [
        "## Step 1: Imports\n",
        "\n",
        "The first step is to import the package numpy and the class LinearRegression from sklearn.linear_model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you have all the functionalities you need to implement linear regression.\n",
        "\n",
        "The fundamental data type of NumPy is the array type called numpy.ndarray. The rest of this article uses the term array to refer to instances of the type numpy.ndarray.\n",
        "\n",
        "The class sklearn.linear_model.LinearRegression will be used to perform linear and polynomial regression and make predictions accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Provide data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Set Information:**\n",
        "We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.\n",
        "\n",
        "**Attribute Information:**\n",
        "The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\n",
        "\n",
        "**Specifically:**\n",
        "- X1 Relative Compactness\n",
        "- X2 Surface Area\n",
        "- X3 Wall Area\n",
        "- X4 Roof Area\n",
        "- X5 Overall Height\n",
        "- X6 Orientation\n",
        "- X7 Glazing Area\n",
        "- X8 Glazing Area Distribution\n",
        "- y1 Heating Load\n",
        "- y2 Cooling Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y1', 'Y2'], dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydata.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(mydata.X1, mydata.Y1)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array(mydata.X1).reshape((-1, 1))\n",
        "y = np.array(mydata.Y1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you have two arrays: the input x and output y. You should call .reshape() on x because this array is required to be two-dimensional, or to be more precise, to have one column and as many rows as necessary. That’s exactly what the argument (-1, 1) of .reshape() specifies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create a model and fit it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This statement creates the variable model as the instance of LinearRegression. You can provide several optional parameters to LinearRegression:\n",
        "\n",
        "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept 𝑏₀ (True) or consider it equal to zero (False).\n",
        "- normalize is a Boolean (False by default) that decides whether to normalize the input variables (True) or not (False).\n",
        "- copy_X is a Boolean (True by default) that decides whether to copy (True) or overwrite the input variables (False).\n",
        "- n_jobs is an integer or None (default) and represents the number of jobs used in parallel computation. None usually means one job and -1 to use all processors.\n",
        "This example uses the default values of all parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With .fit(), you calculate the optimal values of the weights 𝑏₀ and 𝑏₁, using the existing input and output (x and y) as the arguments. In other words, .fit() fits the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Get results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coefficient of determination: 0.3872223619321592\n",
            "intercept: -23.053014060655016\n",
            "slope: [59.35905261]\n"
          ]
        }
      ],
      "source": [
        "r_sq = model.score(x, y)\n",
        "print('coefficient of determination:', r_sq)\n",
        "print('intercept:', model.intercept_)\n",
        "print('slope:', model.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you’re applying .score(), the arguments are also the predictor x and regressor y, and the return value is 𝑅².\n",
        "The code above illustrates how to get 𝑏₀ and 𝑏₁. You can notice that .intercept_ is a scalar, while .coef_ is an array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Predict response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted response:\n",
            "[24.43422803 30.37013329 36.30603855]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict([[0.8],[0.9],[1.0]])\n",
        "print('predicted response:', y_pred, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <font color = #4854E8> Linear Regression With Keras Tansorflow </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X9uIpOS2zx7k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wwJGmDrQ0EoB"
      },
      "source": [
        "## Step 1: Define and Compile the Neural Network\n",
        "\n",
        "Next we will create the simplest possible neural network. It has 1 layer, and that layer has 1 neuron, and the input shape to it is just 1 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kQFAr_xo0M4T"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b825dde1f0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "model2.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "model2.fit(x, y, epochs=1000, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Obtain Parameters/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_5/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[57.70134]], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32, numpy=array([-21.813543], dtype=float32)>]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Predict response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oxNzL4lS2Gui"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "[[24.347528]\n",
            " [30.117662]\n",
            " [35.887794]]\n"
          ]
        }
      ],
      "source": [
        "print(model2.predict([[0.8],[0.9],[1.0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <font color = #4854E8> Linear Regression with statsmodels </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can implement linear regression in Python relatively easily by using the package statsmodels as well. Typically, this is desirable when there is a need for more detailed results.\n",
        "\n",
        "The procedure is similar to that of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import library\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# add column of one\n",
        "x_with_one = sm.add_constant(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to add the column of ones to the inputs if you want statsmodels to calculate the intercept 𝑏₀. It doesn’t takes 𝑏₀ into account by default. That’s how you add the column of ones to x with add_constant(). It takes the input array x as an argument and returns a new array with the column of ones inserted at the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a model and fit it\n",
        "model3 = sm.OLS(y, x_with_one)\n",
        "results = model3.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should be careful here! Please, notice that the first argument is the output, followed with the input. There are several more optional parameters.\n",
        "\n",
        "By calling .fit(), you obtain the variable results, which is an instance of the class statsmodels.regression.linear_model.RegressionResultsWrapper. This object holds a lot of information about the regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.387\n",
            "Model:                            OLS   Adj. R-squared:                  0.386\n",
            "Method:                 Least Squares   F-statistic:                     484.0\n",
            "Date:                Thu, 06 Oct 2022   Prob (F-statistic):           1.59e-83\n",
            "Time:                        16:02:20   Log-Likelihood:                -2676.5\n",
            "No. Observations:                 768   AIC:                             5357.\n",
            "Df Residuals:                     766   BIC:                             5366.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        -23.0530      2.081    -11.076      0.000     -27.139     -18.967\n",
            "x1            59.3591      2.698     22.001      0.000      54.063      64.655\n",
            "==============================================================================\n",
            "Omnibus:                       53.989   Durbin-Watson:                   0.305\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.326\n",
            "Skew:                           0.708   Prob(JB):                     1.08e-14\n",
            "Kurtosis:                       3.059   Cond. No.                         15.0\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Get results\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <font color = #4854E8> Linear Regression Manually </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-23.05301406,  59.35905261])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_x = np.linalg.inv(np.dot(x_with_one.T,x_with_one))\n",
        "x_y = np.dot(x_with_one.T,y)\n",
        "beta = np.dot(x_x,x_y)\n",
        "beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple Linear Regression With statmodels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.916\n",
            "Model:                            OLS   Adj. R-squared:                  0.915\n",
            "Method:                 Least Squares   F-statistic:                     1187.\n",
            "Date:                Thu, 06 Oct 2022   Prob (F-statistic):               0.00\n",
            "Time:                        21:26:19   Log-Likelihood:                -1912.5\n",
            "No. Observations:                 768   AIC:                             3841.\n",
            "Df Residuals:                     760   BIC:                             3878.\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         84.0134     19.034      4.414      0.000      46.649     121.378\n",
            "x1           -64.7734     10.289     -6.295      0.000     -84.973     -44.574\n",
            "x2            -0.0626      0.013     -4.670      0.000      -0.089      -0.036\n",
            "x3             0.0361      0.004      9.386      0.000       0.029       0.044\n",
            "x4            -0.0494      0.008     -6.569      0.000      -0.064      -0.035\n",
            "x5             4.1700      0.338     12.338      0.000       3.506       4.833\n",
            "x6            -0.0233      0.095     -0.246      0.805      -0.209       0.163\n",
            "x7            19.9327      0.814     24.488      0.000      18.335      21.531\n",
            "x8             0.2038      0.070      2.915      0.004       0.067       0.341\n",
            "==============================================================================\n",
            "Omnibus:                       18.647   Durbin-Watson:                   0.654\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.707\n",
            "Skew:                           0.044   Prob(JB):                     6.49e-09\n",
            "Kurtosis:                       4.082   Cond. No.                     1.09e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 3.81e-24. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ],
      "source": [
        "# define new data\n",
        "X = mydata[[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\"]].to_numpy()\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Create a model and fit it\n",
        "model4 = sm.OLS(y, X)\n",
        "results = model4.fit()\n",
        "\n",
        "# Get results\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detecting Multicollinearity with VIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import library\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multicollinearity occurs when there are two or more independent variables in a multiple regression model, which have a high correlation among themselves. When some features are highly correlated, we might have difficulty in distinguishing between their individual effects on the dependent variable. Multicollinearity can be detected using various techniques, one such technique being the Variance Inflation Factor (VIF)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  feature         VIF\n",
            "0      X1  168.948751\n",
            "1      X2         inf\n",
            "2      X3         inf\n",
            "3      X4         inf\n",
            "4      X5  134.035782\n",
            "5      X6   10.796725\n",
            "6      X7    4.293656\n",
            "7      X8    4.496320\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rauzan\\AppData\\Roaming\\Python\\Python38\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        }
      ],
      "source": [
        "# VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = mydata.drop([\"Y1\",\"Y2\"], axis=1).columns\n",
        "  \n",
        "# calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(mydata.drop([\"Y1\",\"Y2\"], axis=1).values, i)\n",
        "                          for i in range(len(mydata.drop([\"Y1\",\"Y2\"], axis=1).columns))]\n",
        "                          \n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple Linear Regression Model After Droping Multicollinearity Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define new data\n",
        "Xclean = mydata[[\"X1\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\"]].to_numpy()\n",
        "Xclean = sm.add_constant(Xclean)\n",
        "\n",
        "# Create a model and fit it\n",
        "model4 = sm.OLS(y, Xclean)\n",
        "results = model4.fit()\n",
        "\n",
        "# Get results\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StepWise, L1, L2, & ElasticNet Regression with scikit-learn ?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab1-for-deeplearn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "427e8c8ef98cfe94ee571c8ec84ec2e7750375cc752cf4db5f715e91bedfb85f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
